{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bda3afcc-8ee5-433d-be1e-77b73484de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Input parameters________________________________________________\n",
    "L0 = 512\n",
    "N_1 = 28\n",
    "N_2 = 352\n",
    "D_1 = L0*0.16\n",
    "D_2 = L0*0.08\n",
    "\n",
    "mu = 0.0240719927\n",
    "rho = 1\n",
    "Re = 100\n",
    "\n",
    "V = L0**3\n",
    "phi_1 = N_1*math.pi*(D_1)**3/(6.*V)\n",
    "phi_2 = N_2*math.pi*(D_2)**3/(6.*V)\n",
    "phi = phi_1 + phi_2\n",
    "x_1 = phi_1/phi\n",
    "x_2 = phi_2/phi\n",
    "eps = 1 - phi\n",
    "D = ((x_1/D_1)+(x_2/D_2))**(-1)\n",
    "y_1 = D_1/D\n",
    "y_2 = D_2/D\n",
    "\n",
    "u_c = (Re * mu) / (rho * D)\n",
    "F_conv = -0.5 * rho * (u_c**2) * ((np.pi * D**2) / 4)\n",
    "F_st = -3 * np.pi * mu * u_c\n",
    "F_c = F_conv\n",
    "T_c = F_c * D\n",
    "\n",
    "Ls = 0.033/L0\n",
    "Ts = 1/10000\n",
    "Ms = 1000/1*Ls**3\n",
    "\n",
    "NN_data_final = np.array([])\n",
    "\n",
    "# loading data________________________________________________________________\n",
    "for kk in range(1,6):\n",
    "    case = \"case\" + str(kk)\n",
    "    mainpath = \"Re\" + str(Re) + \"/\" + str(N_1) + \"-0p16-\" + str(N_2) + \"-0p08/\" + case +\"/initial_position.txt\"\n",
    "    # mainpath = str(N_1) + \"-0p1-\" + str(N_2) + \"-0p05/\" + case +\"/initial_position.txt\"\n",
    "    datafile = pd.read_table(mainpath,delimiter=' ',skiprows=0)\n",
    "\n",
    "    x_pos, y_pos, z_pos = datafile.iloc[:,0].to_numpy(),\\\n",
    "                          datafile.iloc[:,1].to_numpy(),\\\n",
    "                          datafile.iloc[:,2].to_numpy()\n",
    "\n",
    "    r = np.zeros(np.size(x_pos))\n",
    "\n",
    "    mainpath = \"Re\" + str(Re) + \"/\" + str(N_1) + \"-0p16-\" + str(N_2) + \"-0p08/\" + case +\"/force-12000\"\n",
    "    datafile = pd.read_csv(mainpath,delimiter=' ',header=None)\n",
    "\n",
    "    x_force, y_force, z_force = datafile.iloc[:,1].to_numpy(),\\\n",
    "                                datafile.iloc[:,2].to_numpy(),\\\n",
    "                                datafile.iloc[:,3].to_numpy()\n",
    "\n",
    "    x_pos, y_pos, z_pos, r =   x_pos.reshape(-1,1),\\\n",
    "                               y_pos.reshape(-1,1),\\\n",
    "                               z_pos.reshape(-1,1),\\\n",
    "                               r.reshape(-1,1)\n",
    "\n",
    "    x_force, y_force, z_force = x_force.reshape(-1,1),\\\n",
    "                                y_force.reshape(-1,1),\\\n",
    "                                z_force.reshape(-1,1)\n",
    "\n",
    "# non-dimensionalization_____________________________________________________\n",
    "\n",
    "    # x_pos, y_pos, z_pos =   x_pos / (D_2/512),\\\n",
    "    #                         y_pos / (D_2/512),\\\n",
    "    #                         z_pos / (D_2/512)\n",
    "\n",
    "    for i in range(N_1):\n",
    "        x_force[i], y_force[i], z_force[i], r[i] = x_force[i] * eps / F_st / D_1,\\\n",
    "                                                   y_force[i] * eps / F_st / D_1,\\\n",
    "                                                   z_force[i] * eps / F_st / D_1,\\\n",
    "                                                   D_1 / L0 /2\n",
    "    \n",
    "    for i in range(N_1,N_1+N_2):\n",
    "        x_force[i], y_force[i], z_force[i], r[i] = x_force[i] * eps / F_st / D_2,\\\n",
    "                                                   y_force[i] * eps / F_st / D_2,\\\n",
    "                                                   z_force[i] * eps / F_st / D_2,\\\n",
    "                                                   D_2 / L0 /2\n",
    "        \n",
    "#     for i in range(N_1):\n",
    "#         x_force[i], y_force[i], z_force[i], r[i] = 0,\\\n",
    "#                                                    0,\\\n",
    "#                                                    0,\\\n",
    "#                                                    D_1 / L0 /2\n",
    "    \n",
    "#     for i in range(N_1,N_1+N_2):\n",
    "#         x_force[i], y_force[i], z_force[i], r[i] = 0,\\\n",
    "#                                                    0,\\\n",
    "#                                                    0,\\\n",
    "#                                                    D_2 / L0 /2\n",
    "    \n",
    "    # # printing information _____________________________________________________\n",
    "    # F_d_F_st = x_force.mean() * F_c / F_st\n",
    "    # print(f'F_d / F_st \\t= \\t{F_d_F_st:.2f}')\n",
    "    # print(f'sigma_d / F_d \\t= \\t{(x_force.std() / x_force.mean()) * 100:.2f} %')\n",
    "    # F_L = np.hstack((y_force, z_force))\n",
    "    # F_L_mag = np.linalg.norm(F_L, axis=0)\n",
    "    # print(f'F_L / F_st \\t= \\t{F_L.mean():.2g}')\n",
    "    # ratio = F_L.std() / x_force.mean()\n",
    "    # print(f'sigma_L / F_d \\t= \\t{ratio * 100:.2f} %')\n",
    "\n",
    "    # Generate the data matrix with positions_______________________________\n",
    "    xyzr = np.hstack((x_pos, y_pos, z_pos, r))\n",
    "\n",
    "    # The extension of periodic mirror___________________________________\n",
    "    L = 1\n",
    "    delta = 0.5\n",
    "    D = 0.16\n",
    "    n_closest=10\n",
    "\n",
    "    x_back  = xyzr[xyzr[:,0] > (L*delta + D), 0].reshape(-1,1) - L\n",
    "    x_front = xyzr[xyzr[:,0] < (L*delta + D), 0].reshape(-1,1) + L\n",
    "\n",
    "    y_back  = xyzr[xyzr[:,1] > (L*delta + D), 1].reshape(-1,1) - L\n",
    "    y_front = xyzr[xyzr[:,1] < (L*delta + D), 1].reshape(-1,1) + L\n",
    "\n",
    "    z_back  = xyzr[xyzr[:,2] > (L*delta + D), 2].reshape(-1,1) - L\n",
    "    z_front = xyzr[xyzr[:,2] < (L*delta + D), 2].reshape(-1,1) + L\n",
    "\n",
    "    xyzr_x_back    = np.hstack((x_back, y_pos[xyzr[:,0] > (L*delta + D)], z_pos[xyzr[:,0] > (L*delta + D)], r[xyzr[:,0] > (L*delta + D)]))\n",
    "    xyzr_x_front   = np.hstack((x_front, y_pos[xyzr[:,0] < (L*delta + D)], z_pos[xyzr[:,0] < (L*delta + D)], r[xyzr[:,0] < (L*delta + D)]))\n",
    "\n",
    "    xyzr_y_back    = np.hstack((x_pos[xyzr[:,1] > (L*delta + D)], y_back, z_pos[xyzr[:,1] > (L*delta + D)], r[xyzr[:,1] > (L*delta + D)]))\n",
    "    xyzr_y_front   = np.hstack((x_pos[xyzr[:,1] < (L*delta + D)], y_front, z_pos[xyzr[:,1] < (L*delta + D)], r[xyzr[:,1] < (L*delta + D)]))\n",
    "\n",
    "    xyzr_z_back    = np.hstack((x_pos[xyzr[:,2] > (L*delta + D)], y_pos[xyzr[:,2] > (L*delta + D)], z_back, r[xyzr[:,2] > (L*delta + D)]))\n",
    "    xyzr_z_front   = np.hstack((x_pos[xyzr[:,2] < (L*delta + D)], y_pos[xyzr[:,2] < (L*delta + D)], z_front, r[xyzr[:,2] < (L*delta + D)]))\n",
    "\n",
    "    num_p = np.size(xyzr, axis=0)\n",
    "\n",
    "    # here, I add the periodic images to the original xyzr to be considered in the distances\n",
    "    xyzr = np.vstack((xyzr, xyzr_x_back, xyzr_x_front, xyzr_y_back, xyzr_y_front, xyzr_z_back, xyzr_z_front))\n",
    "    # the distance loop should be done over periodic particles as well\n",
    "    num_p_periodic = np.size(xyzr, axis=0)\n",
    "\n",
    "    NN_data = np.zeros( (num_p, 4 * (n_closest - 1) + 10 ) )\n",
    "    \n",
    "    for m in np.arange(num_p):\n",
    "\n",
    "        # Just a progress indicator\n",
    "        if m%100 == 0 and m!=0:\n",
    "            print('Particle '+str(m)+' is done!')\n",
    "\n",
    "        dist  = np.zeros( (num_p_periodic, 5) )\n",
    "\n",
    "        for i in range(num_p_periodic):\n",
    "            dist[i,0] = np.sqrt( ( xyzr[i, 0] - xyzr[m, 0] )**2 +\n",
    "                                 ( xyzr[i, 1] - xyzr[m, 1] )**2 +\n",
    "                                 ( xyzr[i, 2] - xyzr[m, 2] )**2 )\n",
    "            dist[i,1] = xyzr[i, 0] - xyzr[m, 0]\n",
    "            dist[i,2] = xyzr[i, 1] - xyzr[m, 1]\n",
    "            dist[i,3] = xyzr[i, 2] - xyzr[m, 2]\n",
    "            dist[i,4] = xyzr[i, 3]\n",
    "            \n",
    "        dist = dist[ np.argsort( dist[:, 0] ) ]\n",
    "        dist = dist[:n_closest, :]\n",
    "        dist = dist[1:, 1:]\n",
    "        dist = dist.flatten()\n",
    "        dist = dist.reshape(1, -1)\n",
    "\n",
    "        NN_data[m,:dist.size] = dist\n",
    "        \n",
    "        NN_data[m,-10] = xyzr[m, 3]\n",
    "\n",
    "        NN_data[m,-9] = 0\n",
    "        NN_data[m,-8] = 0\n",
    "        NN_data[m,-7] = 0\n",
    "    \n",
    "        NN_data[m,-6] = 0\n",
    "        NN_data[m,-5] = 0\n",
    "        NN_data[m,-4] = 0\n",
    "    \n",
    "        NN_data[m,-3] = x_force[m, 0]\n",
    "        NN_data[m,-2] = y_force[m, 0]\n",
    "        NN_data[m,-1] = z_force[m, 0]\n",
    "        \n",
    "    if kk == 1:\n",
    "        NN_data_final = NN_data\n",
    "    else:\n",
    "        NN_data_final = np.vstack((NN_data_final, NN_data))\n",
    "\n",
    "np.savetxt(\"new_3D_Re100_phi015_M=200\", NN_data_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d2cf5-72bd-474b-b11b-162e5eaa241c",
   "metadata": {},
   "source": [
    "## Local volume fraction ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c59c6-6e8b-487d-a6e6-7c225dd0770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "L0 = 512\n",
    "Re = 10\n",
    "N_1 = 192\n",
    "if N_1 == 192: \n",
    "    N_2 = 768\n",
    "    N_set = 20\n",
    "    D_1 = L0*0.1\n",
    "    D_2 = L0*0.05\n",
    "    c = 4*D_2\n",
    "elif N_1 == 384:\n",
    "    N_2 = 1536\n",
    "    N_set = 10\n",
    "    D_1 = L0*0.1\n",
    "    D_2 = L0*0.05\n",
    "    c = 3*D_2\n",
    "elif N_1 == 313:\n",
    "    N_2 = 1222\n",
    "    N_set = 13\n",
    "    D_1 = L0*0.125\n",
    "    D_2 = L0*0.05\n",
    "    c = 3*D_2\n",
    "elif N_1 == 453:\n",
    "    N_2 = 1528\n",
    "    N_set = 10\n",
    "    D_1 = L0*0.075\n",
    "    D_2 = L0*0.05\n",
    "    c = 4*D_2\n",
    "elif N_1 == 288:\n",
    "    N_2 = 1152\n",
    "    N_set = 10\n",
    "    D_1 = L0*0.1\n",
    "    D_2 = L0*0.05\n",
    "    c = 4*D_2\n",
    "elif N_1 == 393:\n",
    "    N_2 = 1528\n",
    "    N_set = 10\n",
    "    D_1 = L0*0.09\n",
    "    D_2 = L0*0.05\n",
    "    c = 4*D_2\n",
    "case_N = 2\n",
    "\n",
    "print(D_1,D_2)\n",
    "\n",
    "# for kk in range(case_N,case_N+10):\n",
    "for kk in range(case_N,case_N+1):\n",
    "    '''\n",
    "    Reading data from files:\n",
    "    x,y,z_pos          - Coordinates of sphere centers\n",
    "    x,y,z_force/torque - Forces and torques on each sphere\n",
    "    u,v,w_avg          - Local average velocities\n",
    "    phi_local          - Local volume fraction\n",
    "    '''\n",
    "    case = \"case\" + str(kk)\n",
    "    mainpath = \"Uni/Re\" + str(Re) + \"/\" + str(N_1) + \"-\" + str(N_2) + \"/\" + case +\"/initial_position.txt\"\n",
    "    datafile = pd.read_table(mainpath,delimiter=' ',skiprows=0)\n",
    "\n",
    "    x_pos, y_pos, z_pos, r = datafile.iloc[:,0].to_numpy()*L0,\\\n",
    "                             datafile.iloc[:,1].to_numpy()*L0,\\\n",
    "                             datafile.iloc[:,2].to_numpy()*L0,\\\n",
    "                             datafile.iloc[:,3].to_numpy()*L0\n",
    "    \n",
    "    N = x_pos.shape[0]\n",
    "    v_ratio = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        if r[i] == np.max(r):\n",
    "            V_large = r[i]**3\n",
    "            V_small = 0\n",
    "        else:\n",
    "            V_large = 0\n",
    "            V_small = r[i]**3\n",
    "        target = (x_pos[i], y_pos[i], z_pos[i])\n",
    "        # print(i, x_pos[i], y_pos[i], z_pos[i]) \n",
    "        for j in range(N):\n",
    "            if j != i:\n",
    "                local_dist = 1e10\n",
    "                for ii in [-1,0,1]:\n",
    "                    for jj in [-1,0,1]:\n",
    "                        for kk in [-1,0,1]:\n",
    "                            neighbor = (x_pos[j]+ii*L0, y_pos[j]+jj*L0, z_pos[j]+kk*L0)\n",
    "                            local_dist_temp = math.dist(target,neighbor)\n",
    "                            if local_dist_temp < local_dist:\n",
    "                                local_dist = local_dist_temp\n",
    "                if local_dist <= c:\n",
    "                    # print(j, x_pos[j], y_pos[j], z_pos[j], local_dist)\n",
    "                    if r[j] == np.max(r):\n",
    "                        V_large += r[j]**3\n",
    "                    else:\n",
    "                        V_small += r[j]**3\n",
    "        v_ratio[i] = V_large/V_small\n",
    "        print(i,v_ratio[i])\n",
    "print(np.mean(v_ratio[:192]),np.mean(v_ratio[192:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d478e6-bed4-4fd6-b6ce-38d65caca82e",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0cf4b0-88f5-4976-8482-c4ee7ce8261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re                       =   1.00000000\n",
      "Fluid Volume Fraction    =   0.69840711\n",
      "Equivalent Diameter      =  38.40000000\n",
      "x1                       =   0.66666667\n",
      "x2                       =   0.33333333\n",
      "y1/<y>                   =   1.33333333\n",
      "y2/<y>                   =   0.66666667\n",
      "Uc                       =   0.00853333\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 1 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 2 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 3 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 4 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 5 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 6 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 7 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 8 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 9 is done!\n",
      "=========================\n",
      "Particle 100 is done!\n",
      "Particle 200 is done!\n",
      "Particle 300 is done!\n",
      "Particle 400 is done!\n",
      "Particle 500 is done!\n",
      "Particle 600 is done!\n",
      "Particle 700 is done!\n",
      "Particle 800 is done!\n",
      "Particle 900 is done!\n",
      "Particle 1000 is done!\n",
      "Particle 1100 is done!\n",
      "Particle 1200 is done!\n",
      "Particle 1300 is done!\n",
      "Particle 1400 is done!\n",
      "Particle 1500 is done!\n",
      "Particle 1600 is done!\n",
      "Particle 1700 is done!\n",
      "Particle 1800 is done!\n",
      "Particle 1900 is done!\n",
      "=========================\n",
      "Case 10 is done!\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "Input parameters: all parameters are in LB units.\n",
    "L0  - Box size\n",
    "N_1 - Number of large sphere in one realization\n",
    "N_2 - Number of small sphere in one realization\n",
    "D_1 - Large sphere diameter\n",
    "D_2 - small sphere diameter\n",
    "mu  - Dluid dynamic viscosity\n",
    "rho - Fluid density\n",
    "Re  - Reynolds number\n",
    "'''\n",
    "L0 = 512\n",
    "N_1 = 384\n",
    "if N_1 == 192: \n",
    "    N_2 = 768\n",
    "    N_set = 20\n",
    "    D_1 = L0*0.1\n",
    "    D_2 = L0*0.05\n",
    "    c_l = 3*D_2\n",
    "    c_s = 2.5*D_2\n",
    "elif N_1 == 384:\n",
    "    N_2 = 1536\n",
    "    N_set = 10\n",
    "    D_1 = L0*0.1\n",
    "    D_2 = L0*0.05\n",
    "    c_l = 3*D_2\n",
    "    c_s = 2.5*D_2\n",
    "elif N_1 == 313:\n",
    "    N_2 = 1222\n",
    "    N_set = 13\n",
    "    D_1 = L0*0.125\n",
    "    D_2 = L0*0.05\n",
    "    c_l = 5*D_2\n",
    "    c_s = 3*D_2\n",
    "elif N_1 == 453:\n",
    "    N_2 = 1528\n",
    "    N_set = 10\n",
    "    D_1 = L0*0.075\n",
    "    D_2 = L0*0.05\n",
    "    c_l = 5*D_2\n",
    "    c_s = 3.5*D_2\n",
    "elif N_1 == 288:\n",
    "    N_2 = 1152\n",
    "    N_set = 10\n",
    "    D_1 = L0*0.1\n",
    "    D_2 = L0*0.05\n",
    "    c_l = 5*D_2\n",
    "    c_s = 3.5*D_2\n",
    "elif N_1 == 393:\n",
    "    N_2 = 1528\n",
    "    N_set = 10\n",
    "    D_1 = L0*0.09\n",
    "    D_2 = L0*0.05\n",
    "    c_l = 5*D_2\n",
    "    c_s = 3.5*D_2\n",
    "\n",
    "rho = 1\n",
    "phi_sys = 30\n",
    "Re = 1\n",
    "if Re == 100:\n",
    "    mu = 0.0131072\n",
    "elif Re == 40:\n",
    "    mu = 0.02048\n",
    "elif Re == 20:\n",
    "    mu = 0.0524288\n",
    "elif Re == 10:\n",
    "    mu = 0.08192\n",
    "elif Re == 5:\n",
    "    mu = 0.2097152    \n",
    "else:\n",
    "    mu = 0.32768\n",
    "    \n",
    "V = L0**3\n",
    "phi_1 = N_1*math.pi*(D_1)**3/(6.*V)\n",
    "phi_2 = N_2*math.pi*(D_2)**3/(6.*V)\n",
    "phi = phi_1 + phi_2\n",
    "x_1 = phi_1/phi\n",
    "x_2 = phi_2/phi\n",
    "eps = 1 - phi\n",
    "D_eql = ((x_1/D_1)+(x_2/D_2))**(-1)\n",
    "U_c = (Re * mu) / (rho * D_eql)\n",
    "y_1 = D_1/D_eql\n",
    "y_2 = D_2/D_eql\n",
    "\n",
    "print(\"Re                       = {:>12.8f}\".format(Re))\n",
    "print(\"Fluid Volume Fraction    = {:>12.8f}\".format(eps))\n",
    "print(\"Equivalent Diameter      = {:>12.8f}\".format(D_eql))\n",
    "print(\"x1                       = {:>12.8f}\".format(x_1))\n",
    "print(\"x2                       = {:>12.8f}\".format(x_2))\n",
    "print(\"y1/<y>                   = {:>12.8f}\".format(y_1))\n",
    "print(\"y2/<y>                   = {:>12.8f}\".format(y_2))\n",
    "print(\"Uc                       = {:>12.8f}\".format(U_c))\n",
    "\n",
    "NN_data_final = np.array([])\n",
    "\n",
    "case_N = 1\n",
    "n_closest=101\n",
    "origin = (0,0,0)\n",
    "\n",
    "# for kk in range(case_N,case_N+10):\n",
    "for kk in range(case_N,N_set+1):\n",
    "    '''\n",
    "    Reading data from files:\n",
    "    x,y,z_pos          - Coordinates of sphere centers\n",
    "    x,y,z_force/torque - Forces and torques on each sphere\n",
    "    u,v,w_avg          - Local average velocities\n",
    "    phi_local          - Local volume fraction\n",
    "    '''\n",
    "    case = \"case\" + str(kk)\n",
    "    mainpath = \"Uni/Re\" + str(Re) + \"/\" + str(N_1) + \"-\" + str(N_2) + \"/\" + case +\"/initial_position.txt\"\n",
    "    datafile = pd.read_table(mainpath,delimiter=' ',skiprows=0)\n",
    "\n",
    "    x_pos, y_pos, z_pos, r = datafile.iloc[:,0].to_numpy()*L0,\\\n",
    "                             datafile.iloc[:,1].to_numpy()*L0,\\\n",
    "                             datafile.iloc[:,2].to_numpy()*L0,\\\n",
    "                             datafile.iloc[:,3].to_numpy()*L0\n",
    "    \n",
    "    #============================volume fraction ratio================================\n",
    "    N = x_pos.shape[0]\n",
    "    v_ratio = np.zeros(N)\n",
    "    V_large = np.zeros(N)\n",
    "    V_small = np.zeros(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        if r[i] == np.max(r):\n",
    "            V_large[i] = 0#r[i]**3\n",
    "            V_small[i] = 0\n",
    "            c = c_l\n",
    "        else:\n",
    "            V_large[i] = 0\n",
    "            V_small[i] = 0#r[i]**3\n",
    "            c = c_s\n",
    "        target = (x_pos[i], y_pos[i], z_pos[i])\n",
    "        # print(i, x_pos[i], y_pos[i], z_pos[i]) \n",
    "        for j in range(N):\n",
    "            if j != i:\n",
    "                local_dist = 1e10\n",
    "                for iii in [-1,0,1]:\n",
    "                    for jjj in [-1,0,1]:\n",
    "                        for kkk in [-1,0,1]:\n",
    "                            neighbor = (x_pos[j]+iii*L0, y_pos[j]+jjj*L0, z_pos[j]+kkk*L0)\n",
    "                            local_dist_temp = math.dist(target,neighbor)\n",
    "                            if local_dist_temp < local_dist:\n",
    "                                local_dist = local_dist_temp\n",
    "                if local_dist <= c-r[j]:\n",
    "                    # print(j, x_pos[j], y_pos[j], z_pos[j], local_dist)\n",
    "                    if r[j] == np.max(r):\n",
    "                        V_large[i] += r[j]**3\n",
    "                    else:\n",
    "                        V_small[i] += r[j]**3\n",
    "                elif local_dist <= c+r[j]:\n",
    "                    if r[j] == np.max(r):\n",
    "                        V_large[i] += r[j]**3*abs(c-local_dist+r[j])/(2*r[j])\n",
    "                    else:\n",
    "                        V_small[i] += r[j]**3*abs(c-local_dist+r[j])/(2*r[j])\n",
    "        # v_ratio[i] = V_large/V_small\n",
    "        V_large[i] /= c**3\n",
    "        V_small[i] /= c**3\n",
    "    #============================volume fraction ratio================================\n",
    "\n",
    "    mainpath = \"Uni/Re\" + str(Re) + \"/\" + str(N_1) + \"-\" + str(N_2) + \"/\" + case +\"/force-local\"\n",
    "    datafile = pd.read_csv(mainpath,delimiter=' ',header=None)\n",
    "\n",
    "    x_force, y_force, z_force = datafile.iloc[:,1].to_numpy(),\\\n",
    "                                datafile.iloc[:,2].to_numpy(),\\\n",
    "                                datafile.iloc[:,3].to_numpy()\n",
    "    \n",
    "    x_torque, y_torque, z_torque = datafile.iloc[:,4].to_numpy(),\\\n",
    "                                   datafile.iloc[:,5].to_numpy(),\\\n",
    "                                   datafile.iloc[:,6].to_numpy()\n",
    "    \n",
    "    u_avg, v_avg, w_avg = datafile.iloc[:,7].to_numpy(),\\\n",
    "                          datafile.iloc[:,8].to_numpy(),\\\n",
    "                          datafile.iloc[:,9].to_numpy()\n",
    "    \n",
    "    phi_local = datafile.iloc[:,10].to_numpy()\n",
    "    \n",
    "    '''\n",
    "    reshape to have an array with one column:\n",
    "    '''\n",
    "    x_pos, y_pos, z_pos, r =   x_pos.reshape(-1,1),\\\n",
    "                               y_pos.reshape(-1,1),\\\n",
    "                               z_pos.reshape(-1,1),\\\n",
    "                               r.reshape(-1,1)\n",
    "\n",
    "    x_force, y_force, z_force = x_force.reshape(-1,1),\\\n",
    "                                y_force.reshape(-1,1),\\\n",
    "                                z_force.reshape(-1,1)\n",
    "    \n",
    "    x_torque, y_torque, z_torque = x_torque.reshape(-1,1),\\\n",
    "                                   y_torque.reshape(-1,1),\\\n",
    "                                   z_torque.reshape(-1,1)\n",
    "    \n",
    "    phi_local = phi_local.reshape(-1,1)\n",
    "    eps_local = np.ones((phi_local.shape[0],1))-phi_local\n",
    "    \n",
    "    u_avg, v_avg, w_avg = u_avg.reshape(-1,1)*eps_local,\\\n",
    "                          v_avg.reshape(-1,1)*eps_local,\\\n",
    "                          w_avg.reshape(-1,1)*eps_local\n",
    "    \n",
    "    \n",
    "\n",
    "    '''\n",
    "    Non-dimensionalization:\n",
    "    Length scale   - L_scale = D_2\n",
    "    Velocity scale - V_scale = mu/(rho*D_i)\n",
    "    Force scale    - F_scale = 3*pi*mu*D_i*|u|\n",
    "    Torque scale   - T_scale = mu*D_i^2*|u|\n",
    "    '''\n",
    "    for i in range(N_1+N_2):\n",
    "        V_vec = (u_avg[i], v_avg[i], w_avg[i])\n",
    "        V_mag = math.dist(V_vec,origin)\n",
    "        V_scale = mu/(2*r[i])#(1*mu)/(rho*D_eql)#\n",
    "        F_scale = -3*math.pi*mu*r[i]*2*V_mag\n",
    "        T_scale = -mu*(r[i]*2)**2*V_mag\n",
    "        # V_scale = U_c\n",
    "        # # F_scale = -0.5 * rho * (U_c**2) * (np.pi * r[i]**2)\n",
    "        # F_scale = -3*math.pi*mu*r[i]*2*U_c\n",
    "        # T_scale = F_scale*(r[i]*2)\n",
    "        x_force[i], y_force[i], z_force[i] = x_force[i] / F_scale,\\\n",
    "                                             y_force[i] / F_scale,\\\n",
    "                                             z_force[i] / F_scale,\\\n",
    "\n",
    "        x_torque[i], y_torque[i], z_torque[i] = x_torque[i] / T_scale,\\\n",
    "                                                y_torque[i] / T_scale,\\\n",
    "                                                z_torque[i] / T_scale\n",
    "        \n",
    "        u_avg[i], v_avg[i], w_avg[i] = u_avg[i] / V_scale,\\\n",
    "                                       v_avg[i] / V_scale,\\\n",
    "                                       w_avg[i] / V_scale,\\\n",
    "\n",
    "    x_pos, y_pos, z_pos, r = x_pos / (D_2),\\\n",
    "                             y_pos / (D_2),\\\n",
    "                             z_pos / (D_2),\\\n",
    "                             r / (D_2)\n",
    "\n",
    "    '''\n",
    "    Generate the data matrix with positions:\n",
    "    '''\n",
    "    xyzr = np.hstack((x_pos, y_pos, z_pos, r))\n",
    "    num_p = np.size(xyzr, axis=0)\n",
    "\n",
    "    '''\n",
    "    The extension of periodic mirror:\n",
    "    '''\n",
    "    L = L0/D_2\n",
    "    delta = 0.5\n",
    "    D = 2\n",
    "    \n",
    "    xyzr_periodic = np.zeros([num_p,4,26])\n",
    "    \n",
    "    periodic_index = 0\n",
    "    for i in [-1,0,1]:\n",
    "        for j in [-1,0,1]:\n",
    "            for k in [-1,0,1]:\n",
    "                if ((i == 0 and j == 0 and k == 0)==False):\n",
    "                    xyzr_periodic[:,:,periodic_index] = xyzr+np.tile([i,j,k,0],[num_p,1])*L\n",
    "                    periodic_index += 1\n",
    "\n",
    "#     x_back  = xyzr[xyzr[:,0] > (L*delta + D), 0].reshape(-1,1) - L\n",
    "#     x_front = xyzr[xyzr[:,0] < (L*delta + D), 0].reshape(-1,1) + L\n",
    "\n",
    "#     y_back  = xyzr[xyzr[:,1] > (L*delta + D), 1].reshape(-1,1) - L\n",
    "#     y_front = xyzr[xyzr[:,1] < (L*delta + D), 1].reshape(-1,1) + L\n",
    "\n",
    "#     z_back  = xyzr[xyzr[:,2] > (L*delta + D), 2].reshape(-1,1) - L\n",
    "#     z_front = xyzr[xyzr[:,2] < (L*delta + D), 2].reshape(-1,1) + L\n",
    "\n",
    "#     xyzr_x_back    = np.hstack((x_back, y_pos[xyzr[:,0] > (L*delta + D)], z_pos[xyzr[:,0] > (L*delta + D)], r[xyzr[:,0] > (L*delta + D)]))\n",
    "#     xyzr_x_front   = np.hstack((x_front, y_pos[xyzr[:,0] < (L*delta + D)], z_pos[xyzr[:,0] < (L*delta + D)], r[xyzr[:,0] < (L*delta + D)]))\n",
    "\n",
    "#     xyzr_y_back    = np.hstack((x_pos[xyzr[:,1] > (L*delta + D)], y_back, z_pos[xyzr[:,1] > (L*delta + D)], r[xyzr[:,1] > (L*delta + D)]))\n",
    "#     xyzr_y_front   = np.hstack((x_pos[xyzr[:,1] < (L*delta + D)], y_front, z_pos[xyzr[:,1] < (L*delta + D)], r[xyzr[:,1] < (L*delta + D)]))\n",
    "\n",
    "#     xyzr_z_back    = np.hstack((x_pos[xyzr[:,2] > (L*delta + D)], y_pos[xyzr[:,2] > (L*delta + D)], z_back, r[xyzr[:,2] > (L*delta + D)]))\n",
    "#     xyzr_z_front   = np.hstack((x_pos[xyzr[:,2] < (L*delta + D)], y_pos[xyzr[:,2] < (L*delta + D)], z_front, r[xyzr[:,2] < (L*delta + D)]))\n",
    "\n",
    "    '''\n",
    "    Add periodic boxes to the original domain\n",
    "    '''\n",
    "    for i in range(26):\n",
    "        xyzr = np.vstack((xyzr,xyzr_periodic[:,:,i]))\n",
    "        \n",
    "    xyzr = xyzr[xyzr[:,0]>(D-L/3)]\n",
    "    xyzr = xyzr[xyzr[:,0]<(D+4*L/3)]\n",
    "    xyzr = xyzr[xyzr[:,1]>(D-L/3)]\n",
    "    xyzr = xyzr[xyzr[:,1]<(D+4*L/3)]\n",
    "    xyzr = xyzr[xyzr[:,2]>(D-L/3)]\n",
    "    xyzr = xyzr[xyzr[:,2]<(D+4*L/3)]\n",
    "        \n",
    "    '''\n",
    "    The distance loop should be done over periodic particles as well\n",
    "    '''\n",
    "    num_p_periodic = np.size(xyzr, axis=0)\n",
    "\n",
    "    NN_data = np.zeros( (num_p, 4 * (n_closest - 1) + 12 ) )\n",
    "    \n",
    "    for m in np.arange(num_p):\n",
    "\n",
    "        # Just a progress indicator\n",
    "        if m%100 == 0 and m!=0:\n",
    "            print('Particle '+str(m)+' is done!')\n",
    "\n",
    "        dist  = np.zeros( (num_p_periodic, 5) )\n",
    "\n",
    "        for i in range(num_p_periodic):\n",
    "            dist[i,0] = np.sqrt( ( xyzr[i, 0] - xyzr[m, 0] )**2 +\n",
    "                                 ( xyzr[i, 1] - xyzr[m, 1] )**2 +\n",
    "                                 ( xyzr[i, 2] - xyzr[m, 2] )**2 )\n",
    "            dist[i,1] = xyzr[i, 0] - xyzr[m, 0]\n",
    "            dist[i,2] = xyzr[i, 1] - xyzr[m, 1]\n",
    "            dist[i,3] = xyzr[i, 2] - xyzr[m, 2]\n",
    "            dist[i,4] = xyzr[i, 3]\n",
    "            \n",
    "        dist = dist[ np.argsort( dist[:, 0] ) ]\n",
    "        dist = dist[:n_closest, :]\n",
    "        dist = dist[1:, 1:]\n",
    "        dist = dist.flatten()\n",
    "        dist = dist.reshape(1, -1)\n",
    "\n",
    "        NN_data[m,:dist.size] = dist\n",
    "        \n",
    "        NN_data[m,-12] = xyzr[m, 3]\n",
    "        NN_data[m,-11] = V_large[m]#phi_local[m]*v_ratio[m]/(v_ratio[m]+1)\n",
    "        NN_data[m,-10] = V_small[m]#phi_local[m]/(v_ratio[m]+1)\n",
    "\n",
    "        NN_data[m,-9] = u_avg[m]\n",
    "        NN_data[m,-8] = v_avg[m]\n",
    "        NN_data[m,-7] = w_avg[m]\n",
    "    \n",
    "        NN_data[m,-6] = x_torque[m]\n",
    "        NN_data[m,-5] = y_torque[m]\n",
    "        NN_data[m,-4] = z_torque[m]\n",
    "    \n",
    "        NN_data[m,-3] = x_force[m]\n",
    "        NN_data[m,-2] = y_force[m]\n",
    "        NN_data[m,-1] = z_force[m]\n",
    "        \n",
    "    if kk == case_N:\n",
    "        NN_data_final = NN_data\n",
    "    else:\n",
    "        NN_data_final = np.vstack((NN_data_final, NN_data))\n",
    "        \n",
    "    print('=========================')    \n",
    "    print('Case '+str(kk)+' is done!')\n",
    "    print('=========================') \n",
    "\n",
    "np.savetxt(f\"Datasets/Full_c_Re{Re}_phi0{phi_sys}_M={n_closest}_{N_1}L\", NN_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93efd31c-60a4-4b95-9c85-c5daa0910593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]] 1\n",
      "[[-1 -1  0]\n",
      " [-1 -1  0]\n",
      " [-1 -1  0]] 2\n",
      "[[-1 -1  1]\n",
      " [-1 -1  1]\n",
      " [-1 -1  1]] 3\n",
      "[[-1  0 -1]\n",
      " [-1  0 -1]\n",
      " [-1  0 -1]] 4\n",
      "[[-1  0  0]\n",
      " [-1  0  0]\n",
      " [-1  0  0]] 5\n",
      "[[-1  0  1]\n",
      " [-1  0  1]\n",
      " [-1  0  1]] 6\n",
      "[[-1  1 -1]\n",
      " [-1  1 -1]\n",
      " [-1  1 -1]] 7\n",
      "[[-1  1  0]\n",
      " [-1  1  0]\n",
      " [-1  1  0]] 8\n",
      "[[-1  1  1]\n",
      " [-1  1  1]\n",
      " [-1  1  1]] 9\n",
      "[[ 0 -1 -1]\n",
      " [ 0 -1 -1]\n",
      " [ 0 -1 -1]] 10\n",
      "[[ 0 -1  0]\n",
      " [ 0 -1  0]\n",
      " [ 0 -1  0]] 11\n",
      "[[ 0 -1  1]\n",
      " [ 0 -1  1]\n",
      " [ 0 -1  1]] 12\n",
      "[[ 0  0 -1]\n",
      " [ 0  0 -1]\n",
      " [ 0  0 -1]] 13\n",
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] 14\n",
      "[[ 0  1 -1]\n",
      " [ 0  1 -1]\n",
      " [ 0  1 -1]] 15\n",
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]] 16\n",
      "[[0 1 1]\n",
      " [0 1 1]\n",
      " [0 1 1]] 17\n",
      "[[ 1 -1 -1]\n",
      " [ 1 -1 -1]\n",
      " [ 1 -1 -1]] 18\n",
      "[[ 1 -1  0]\n",
      " [ 1 -1  0]\n",
      " [ 1 -1  0]] 19\n",
      "[[ 1 -1  1]\n",
      " [ 1 -1  1]\n",
      " [ 1 -1  1]] 20\n",
      "[[ 1  0 -1]\n",
      " [ 1  0 -1]\n",
      " [ 1  0 -1]] 21\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] 22\n",
      "[[1 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]] 23\n",
      "[[ 1  1 -1]\n",
      " [ 1  1 -1]\n",
      " [ 1  1 -1]] 24\n",
      "[[1 1 0]\n",
      " [1 1 0]\n",
      " [1 1 0]] 25\n",
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]] 26\n"
     ]
    }
   ],
   "source": [
    "# a = np.array([[2,3,4],\n",
    "#               [5,6,7]])\n",
    "# print(a[::1,:np.size(a,axis=1)-1])\n",
    "v = np.array([[1,2],[3,4]])\n",
    "a = 0\n",
    "for i in [-1,0,1]:\n",
    "    for j in [-1,0,1]:\n",
    "        for k in [-1,0,1]:\n",
    "            if ((i == 0 and j == 0 and k == 0)==False):\n",
    "                b = np.tile([i,j,k],[3,1])\n",
    "                a += 1\n",
    "                print(b,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b34d4-71b9-4ae8-994a-975fa53cc08c",
   "metadata": {},
   "source": [
    "## Average and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5ac0fd-6b60-4351-bacd-842febd6943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15360\n",
      "15360\n",
      "=============Mean values=============\n",
      "Large particle F_x mean  =  15.089332\n",
      "Large particle F_y mean  =  -0.042260\n",
      "Large particle F_z mean  =   0.003258\n",
      "Large particle T_x mean  =   0.000199\n",
      "Large particle T_y mean  =  -0.002075\n",
      "Large particle T_z mean  =   0.003912\n",
      "Small particle F_x mean  =   7.567062\n",
      "Small particle F_y mean  =   0.018419\n",
      "Small particle F_z mean  =  -0.000693\n",
      "Small particle T_x mean  =  -0.000033\n",
      "Small particle T_y mean  =  -0.000994\n",
      "Small particle T_z mean  =  -0.000896\n",
      "=========Standard Deviations=========\n",
      "Large particle F_x std   =   3.135263\n",
      "Large particle F_y std   =   2.106473\n",
      "Large particle F_z std   =   2.136747\n",
      "Large particle T_x std   =   0.065781\n",
      "Large particle T_y std   =   0.207591\n",
      "Large particle T_z std   =   0.204546\n",
      "Small particle F_x std   =   2.510142\n",
      "Small particle F_y std   =   1.421573\n",
      "Small particle F_z std   =   1.415807\n",
      "Small particle T_x std   =   0.050616\n",
      "Small particle T_y std   =   0.144847\n",
      "Small particle T_z std   =   0.143566\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "N_1 = 192\n",
    "N_2 = 768\n",
    "\n",
    "L = 512\n",
    "D_1 = L*0.1\n",
    "D_2 = L*0.05\n",
    "NOR = 20\n",
    "\n",
    "V = L**3\n",
    "phi_1 = N_1*math.pi*(D_1)**3/(6.*V)\n",
    "phi_2 = N_2*math.pi*(D_2)**3/(6.*V)\n",
    "phi = phi_1 + phi_2\n",
    "x_1 = phi_1/phi\n",
    "x_2 = phi_2/phi\n",
    "eps = 1 - phi\n",
    "D = ((x_1/D_1)+(x_2/D_2))**(-1)\n",
    "y_1 = D_1/D\n",
    "y_2 = D_2/D\n",
    "\n",
    "Re = 100\n",
    "if Re == 100:\n",
    "    nu = 0.0131072\n",
    "else:\n",
    "    nu = 0.32768\n",
    "u  = Re * nu / D\n",
    "\n",
    "num_par = (N_1+N_2)*NOR\n",
    "F_l = np.zeros((N_1*NOR,6))\n",
    "F_s = np.zeros((N_2*NOR,6))\n",
    "T_l = np.zeros((N_1*NOR,6))\n",
    "T_s = np.zeros((N_2*NOR,6))\n",
    "\n",
    "F_conv_1 = -0.5 * (u**2) * ((np.pi * D_1**2) / 4)\n",
    "F_conv_2 = -0.5 * (u**2) * ((np.pi * D_2**2) / 4)\n",
    "F_st = -3 * np.pi * nu * u \n",
    "F_c_1 = -3 * np.pi * nu * u * D_1\n",
    "F_c_2 = -3 * np.pi * nu * u * D_2\n",
    "T_c_1 = F_c_1 * D_1\n",
    "T_c_2 = F_c_2 * D_2\n",
    "\n",
    "for j in range(1,NOR+1):\n",
    "    case = \"case\" + str(j)\n",
    "    mainpath = \"Uni/Re\" + str(Re) + \"/\" + str(N_1) + \"-\" + str(N_2) + \"/\" + case +\"/force-local\"\n",
    "\n",
    "    # #species 1\n",
    "    # for i in range(0,N_1):\n",
    "    datafile = pd.read_table(mainpath,delimiter=' ',header=None).to_numpy()\n",
    "    F_l[(j-1)*N_1:j*N_1,0:3] = datafile[0:N_1,1:4]/F_c_1\n",
    "    T_l[(j-1)*N_1:j*N_1,0:3] = datafile[0:N_1,4:7]/T_c_1\n",
    "    F_s[(j-1)*N_2:j*N_2,0:3] = datafile[N_1:N_1+N_2,1:4]/F_c_2\n",
    "    T_s[(j-1)*N_2:j*N_2,0:3] = datafile[N_1:N_1+N_2,4:7]/T_c_2\n",
    "\n",
    "print(T_s.shape[0])\n",
    "# T_l = T_l[abs(T_l[:,2])<0.8]\n",
    "# T_s = T_s[abs(T_s[:,2])<0.6]\n",
    "print(T_s.shape[0])\n",
    "\n",
    "print(\"=============Mean values=============\")\n",
    "print(\"Large particle F_x mean  = {:>10.6f}\".format(np.mean(F_l[:,0])))\n",
    "print(\"Large particle F_y mean  = {:>10.6f}\".format(np.mean(F_l[:,1])))\n",
    "print(\"Large particle F_z mean  = {:>10.6f}\".format(np.mean(F_l[:,2])))\n",
    "print(\"Large particle T_x mean  = {:>10.6f}\".format(np.mean(T_l[:,0])))\n",
    "print(\"Large particle T_y mean  = {:>10.6f}\".format(np.mean(T_l[:,1])))\n",
    "print(\"Large particle T_z mean  = {:>10.6f}\".format(np.mean(T_l[:,2])))\n",
    "print(\"Small particle F_x mean  = {:>10.6f}\".format(np.mean(F_s[:,0])))\n",
    "print(\"Small particle F_y mean  = {:>10.6f}\".format(np.mean(F_s[:,1])))\n",
    "print(\"Small particle F_z mean  = {:>10.6f}\".format(np.mean(F_s[:,2])))\n",
    "print(\"Small particle T_x mean  = {:>10.6f}\".format(np.mean(T_s[:,0])))\n",
    "print(\"Small particle T_y mean  = {:>10.6f}\".format(np.mean(T_s[:,1])))\n",
    "print(\"Small particle T_z mean  = {:>10.6f}\".format(np.mean(T_s[:,2])))\n",
    "print(\"=========Standard Deviations=========\")\n",
    "print(\"Large particle F_x std   = {:>10.6f}\".format(np.std(F_l[:,0])))\n",
    "print(\"Large particle F_y std   = {:>10.6f}\".format(np.std(F_l[:,1])))\n",
    "print(\"Large particle F_z std   = {:>10.6f}\".format(np.std(F_l[:,2])))\n",
    "print(\"Large particle T_x std   = {:>10.6f}\".format(np.std(T_l[:,0])))\n",
    "print(\"Large particle T_y std   = {:>10.6f}\".format(np.std(T_l[:,1])))\n",
    "print(\"Large particle T_z std   = {:>10.6f}\".format(np.std(T_l[:,2])))\n",
    "print(\"Small particle F_x std   = {:>10.6f}\".format(np.std(F_s[:,0])))\n",
    "print(\"Small particle F_y std   = {:>10.6f}\".format(np.std(F_s[:,1])))\n",
    "print(\"Small particle F_z std   = {:>10.6f}\".format(np.std(F_s[:,2])))\n",
    "print(\"Small particle T_x std   = {:>10.6f}\".format(np.std(T_s[:,0])))\n",
    "print(\"Small particle T_y std   = {:>10.6f}\".format(np.std(T_s[:,1])))\n",
    "print(\"Small particle T_z std   = {:>10.6f}\".format(np.std(T_s[:,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba60e9b-8da7-4ec6-9b3b-ba24d2146aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
